# Few-Shot-and-Zero-Shot-Learning
Few-shot learning aims to train models with very few labeled examples, while zero-shot learning enables models to generalize to unseen classes based on learned semantic relationships. These approaches are becoming increasingly important in real-world tasks where labeled data is hard to obtain.

# Fewâ€‘Shot & Zeroâ€‘Shot Learning on CIFARâ€‘10

This repository demonstrates both fewâ€‘shot and zeroâ€‘shot classification on CIFARâ€‘10:

* **Fewâ€‘Shot**: Train a linear classifier on top of a frozen ResNetâ€‘18 backbone using only 1, 5, or 10 labeled examples per class.
* **Zeroâ€‘Shot**: Use OpenAIâ€™s CLIP (ViTâ€‘B/32) to classify CIFARâ€‘10 images without any training on the task.


## ğŸš€ Features

* **Data Loading**

  * CIFARâ€‘10 train/test split with standard normalization and resizing.
* **Fewâ€‘Shot Pipeline**

  * Sample `K` shots per class from the training set.
  * Extract features via pretrained ResNetâ€‘18 (backbone).
  * Train a lightweight linear head.
  * Evaluate on the full CIFARâ€‘10 test set.
* **Zeroâ€‘Shot Pipeline**

  * Encode class names with CLIPâ€™s text encoder.
  * Encode test images with CLIPâ€™s image encoder.
  * Compute cosine similarities for classification.
* **Visualization**

  * Bar chart comparing accuracies of 1â€‘shot, 5â€‘shot, 10â€‘shot, and zeroâ€‘shot.



## ğŸ“‹ Requirements

* PythonÂ 3.7+
* PyTorchÂ 1.10+ & TorchVisionÂ 0.11+
* TransformersÂ 4.10+
* matplotlib
* tqdm

Install with:

```bash
pip install torch torchvision transformers matplotlib tqdm
```



## ğŸ“ File

* `few_zero_learning.py`
  Full endâ€‘toâ€‘end script. Contains data loading, fewâ€‘shot & zeroâ€‘shot routines, evaluation, and plotting.


## â–¶ï¸ Usage

1. **Download dependencies**:

   ```bash
   pip install torch torchvision transformers matplotlib tqdm
   ```

2. **Run the script**:

   ```bash
   python few_zero_learning.py
   ```

   * Downloads CIFARâ€‘10 automatically.
   * Prints 1â€‘shot, 5â€‘shot, 10â€‘shot, and zeroâ€‘shot accuracies.
   * Saves a bar chart as `outputs/few_zero_shot_comparison.png`.



## ğŸ“Š Example Output

```
=== 1â€‘shot experiment ===
1â€‘shot test accuracy: 15.20%
=== 5â€‘shot experiment ===
5â€‘shot test accuracy: 35.40%
=== 10â€‘shot experiment ===
10â€‘shot test accuracy: 50.85%

=== zeroâ€‘shot via CLIP ===
zeroâ€‘shot test accuracy: 29.73%
```

![Comparison Plot](outputs/few_zero_shot_comparison.png)


## ğŸ” Notes

* Fewâ€‘shot models train **only** the final linear layer; backbone is frozen.
* Zeroâ€‘shot uses standard CLIP prompts:

  > â€œa photo of a {class\_name}â€
* Results may vary depending on hardware and random seed.


## ğŸ§ª Reproducibility

* Random seed is fixed (`42`) for both PyTorch and NumPy.
* Batch size, learning rate, and epochs are configurable at the top of the script.
